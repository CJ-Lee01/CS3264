{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb8ab8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import shap\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from peft import PeftModel\n",
    "from shap.maskers import Text\n",
    "import torch.nn.functional as F\n",
    "from termcolor import colored\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Setup NLTK ===\n",
    "nltk_data_path = os.path.join(os.getcwd(), 'nltk_data')\n",
    "os.makedirs(nltk_data_path, exist_ok=True)\n",
    "try:\n",
    "    nltk.download('punkt_tab', download_dir=nltk_data_path)\n",
    "except:\n",
    "    nltk.download('punkt', download_dir=nltk_data_path)\n",
    "nltk.data.path.append(nltk_data_path)\n",
    "\n",
    "# === Device setup ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\U0001F680 Using device: {device}\")\n",
    "\n",
    "# === Load tokenizer and model ===\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "base_model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "model = PeftModel.from_pretrained(base_model, \"./trained_distilbert_lora\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# === Wrapped model for SHAP ===\n",
    "def wrapped_model(texts):\n",
    "    if isinstance(texts, (str, np.generic)) or not isinstance(texts, list):\n",
    "        texts = [str(t) for t in np.atleast_1d(texts)]\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# === Table Formatter ===\n",
    "def truncate(text, length=80):\n",
    "    return text if len(text) <= length else text[:length - 3] + \"...\"\n",
    "\n",
    "def color_class(cls):\n",
    "    return colored(cls, 'green') if cls == 'REAL' else colored(cls, 'red')\n",
    "\n",
    "def color_score(score):\n",
    "    return colored(f\"{score:+.4f}\", 'green' if score >= 0 else 'red')\n",
    "\n",
    "def print_table(rows, headers):\n",
    "    col_widths = [max(len(truncate(str(row[i]))) for row in rows + [headers]) + 2 for i in range(len(headers))]\n",
    "    header_line = \" | \".join(h.ljust(col_widths[i]) for i, h in enumerate(headers))\n",
    "    print(\"\\n\" + \"=\" * len(header_line))\n",
    "    print(header_line)\n",
    "    print(\"-\" * len(header_line))\n",
    "    for row in rows:\n",
    "        print(\" | \".join(truncate(str(row[i])).ljust(col_widths[i]) for i in range(len(row))))\n",
    "    print(\"=\" * len(header_line))\n",
    "\n",
    "# === SHAP Explain â€” Sentences vs Article ===\n",
    "def shap_sentence_vs_article(article_text, threshold=0.05):\n",
    "    print(f\"\\nðŸ” Mode: Sentence-wise explanation vs Article\")\n",
    "\n",
    "    # Sentence-level chunks\n",
    "    chunks = sent_tokenize(article_text)\n",
    "    explainer = shap.Explainer(wrapped_model, Text(tokenizer))\n",
    "    shap_values = explainer(chunks)\n",
    "\n",
    "    # Full-article prediction\n",
    "    article_pred_class = np.argmax(wrapped_model([article_text])[0])\n",
    "    class_name = ['FAKE', 'REAL'][article_pred_class]\n",
    "    print(f\"\\nðŸŽ¯ Predicted Class for Full Article: {color_class(class_name)}\\n\")\n",
    "\n",
    "    table_rows = []\n",
    "    flagged_sentences = []\n",
    "\n",
    "    for i, (chunk, shap_val) in enumerate(tqdm(zip(chunks, shap_values.values), total=len(chunks), desc=\"ðŸ”Ž Explaining\")):\n",
    "        score = shap_val[:, article_pred_class].sum()\n",
    "        score_colored = color_score(score)\n",
    "\n",
    "        # Store for table\n",
    "        table_rows.append([f\"Sentence {i+1}\", chunk.strip(), score_colored])\n",
    "\n",
    "        # Highlight flagged sentence if it strongly contributes to FAKE\n",
    "        if article_pred_class == 0 and score > threshold:\n",
    "            flagged_sentences.append(colored(f\"[SUSPECTED FAKE] Sentence {i+1}: {chunk.strip()}\", 'red'))\n",
    "        elif article_pred_class == 1 and score > threshold:\n",
    "            flagged_sentences.append(colored(f\"[REAL âžœ slightly FAKE-ish] Sentence {i+1}: {chunk.strip()}\", 'yellow'))\n",
    "\n",
    "    # Print SHAP score table\n",
    "    print_table(table_rows, headers=[\"Chunk\", \"Content\", f\"SHAP â†’ {class_name}\"])\n",
    "\n",
    "    # === Print full paragraph with inline highlights ===\n",
    "    print(f\"\\nðŸ“„ Full Article with Highlighted Sentences (Threshold: {threshold}):\\n\")\n",
    "\n",
    "    highlighted_article = []\n",
    "    for i, (chunk, shap_val) in enumerate(zip(chunks, shap_values.values)):\n",
    "        score = shap_val[:, article_pred_class].sum()\n",
    "        if article_pred_class == 0 and score < threshold:\n",
    "            highlighted_article.append(colored(chunk.strip(), 'red'))\n",
    "        elif article_pred_class == 1 and score < threshold:\n",
    "            highlighted_article.append(colored(chunk.strip(), 'yellow'))\n",
    "        else:\n",
    "            highlighted_article.append(chunk.strip())\n",
    "\n",
    "    print(\" \".join(highlighted_article))\n",
    "\n",
    "    # === Show flagged sentence list for reference ===\n",
    "    if flagged_sentences:\n",
    "        print(f\"\\nðŸš¨ Highlighted Sentences (Score > {threshold}):\\n\")\n",
    "        for s in flagged_sentences:\n",
    "            print(s)\n",
    "    else:\n",
    "        print(f\"\\nâœ… No sentences passed the threshold for suspicion (Score > {threshold})\")\n",
    "\n",
    "# === Batch run multiple examples ===\n",
    "if __name__ == \"__main__\":\n",
    "    examples = [\n",
    "        # Health misinformation and facts\n",
    "        \"\"\"A viral post claims that drinking warm lemon water every morning cures cancer by 'alkalizing the body' and eliminating harmful toxins.\n",
    "        While lemons are a good source of vitamin C and may support immunity, there is no scientific evidence that they cure cancer or significantly change blood pH.\n",
    "        Oncologists emphasize that such claims can be dangerous if they lead patients to forgo evidence-based treatments like chemotherapy or radiation.\"\"\",\n",
    "\n",
    "        # AI sentience myth vs expert opinion\n",
    "        \"\"\"Recent headlines suggest that AI systems like ChatGPT have become fully sentient, capable of experiencing emotions and forming independent opinions.\n",
    "        However, experts from OpenAI and academic institutions clarify that these systems are large-scale language models trained on massive datasetsâ€”they simulate understanding but do not possess consciousness.\n",
    "        Studies confirm that while LLMs can generate human-like responses, their outputs are the result of pattern recognition, not awareness.\"\"\",\n",
    "\n",
    "        # Financial conspiracy vs reality\n",
    "        \"\"\"A popular financial influencer claims that the U.S. Federal Reserve is intentionally printing money to crash the dollar and usher in a new digital currency under global control.\n",
    "        While the Fed has indeed increased money supply during times of crisis, such as the 2008 recession and COVID-19 pandemic, there is no evidence of a coordinated plan to collapse the economy.\n",
    "        Central bank digital currencies (CBDCs) are being explored worldwide, but their adoption is guided by transparency, not secrecy.\"\"\",\n",
    "\n",
    "        # Education disinfo\n",
    "        \"\"\"Some articles claim that standardized tests like the SAT are part of a global intelligence-tracking system funded by secret government agencies.\n",
    "        In reality, the SAT was developed to assess readiness for college and has undergone numerous reforms to reduce bias.\n",
    "        While criticisms remain, there is no evidence it is used to feed data to intelligence organizations.\"\"\",\n",
    "\n",
    "        # Vaccine chip hoax\n",
    "        \"\"\"A widely circulated video alleges that COVID-19 vaccines contain microchips for government surveillance.\n",
    "        This claim has been debunked by multiple independent investigations and health agencies.\n",
    "        Vaccine ingredients are publicly disclosed, and no approved vaccine contains microchips or tracking devices.\"\"\",\n",
    "\n",
    "        # Space hoax mixed with verified info\n",
    "        \"\"\"A forum thread suggests that the Mars rover images are actually filmed in a desert in Nevada.\n",
    "        NASA has consistently published telemetry, satellite data, and photographic evidence to support its missions.\n",
    "        Thousands of engineers and scientists across international agencies have confirmed the integrity of Mars exploration missions.\"\"\",\n",
    "\n",
    "        # Nutrition fact + exaggeration\n",
    "        \"\"\"Some influencers say eating only raw vegetables for 30 days can reverse autoimmune disorders.\n",
    "        While vegetables are a crucial part of a healthy diet, there is no conclusive evidence that raw-only diets cure autoimmune diseases.\n",
    "        Doctors advise balanced nutrition and caution against extreme dietary restrictions.\"\"\",\n",
    "\n",
    "        # Climate change denial myth\n",
    "        \"\"\"A blog post argues that recent cold winters prove that climate change is a hoax.\n",
    "        However, climate scientists explain that global warming can disrupt weather patterns and lead to increased frequency of extreme eventsâ€”including cold snaps.\n",
    "        Long-term temperature trends, not short-term events, determine climate patterns.\"\"\",\n",
    "\n",
    "        # Education tech fear\n",
    "        \"\"\"A TikTok video claims that digital textbooks are a tool for governments to control student thoughts.\n",
    "        Digital education tools are designed to increase access and reduce costs, not manipulate beliefs.\n",
    "        Content is often curated by educators and reviewed by academic institutions.\"\"\",\n",
    "\n",
    "        # Historical revisionism\n",
    "        \"\"\"A viral claim says the moon landing never happened and was staged in a Hollywood studio.\n",
    "        However, physical evidence like moon rocks, engineering blueprints, and decades of third-party tracking contradict this.\n",
    "        Multiple space agencies, including Russiaâ€™s, acknowledged the success of Apollo missions at the time.\"\"\"\n",
    "    ]\n",
    "\n",
    "    for idx, article in enumerate(examples):\n",
    "        print(f\"\\n\\n================ EXAMPLE {idx + 1} ================\\n\")\n",
    "        shap_sentence_vs_article(article)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
