{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\cs3264\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded with 72134 entries.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import joblib\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from dataloading import get_hasib18_fns\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "# Text preprocessing function (same as in training)\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def load_dataset():\n",
    "    \"\"\"Load the original dataset used for training\"\"\"\n",
    "    train_df, test_df = get_hasib18_fns()\n",
    "    \n",
    "    # Preprocess text\n",
    "    train_df['processed_text'] = train_df['text'].apply(preprocess_text)\n",
    "    test_df['processed_text'] = test_df['text'].apply(preprocess_text)\n",
    "    \n",
    "    # Concatenate for full dataset\n",
    "    full_df = pd.concat([train_df, test_df], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    return full_df\n",
    "\n",
    "# Load dataset only once\n",
    "print(\"Loading dataset...\")\n",
    "dataset = load_dataset()\n",
    "print(f\"Dataset loaded with {len(dataset)} entries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model_type, index=None):\n",
    "    \"\"\"\n",
    "    Run inference on a specific entry using the preloaded dataset.\n",
    "    \n",
    "    Args:\n",
    "        model_type: 'gru', 'lstm', or 'svm'\n",
    "        index: Specific index to run inference on (optional)\n",
    "    \"\"\"\n",
    "    model_dir = 'models'\n",
    "    \n",
    "    if index is not None:\n",
    "        if index < 0 or index >= len(dataset):\n",
    "            print(f\"Error: Index {index} is out of bounds. Dataset has {len(dataset)} entries.\")\n",
    "            return\n",
    "    \n",
    "    if model_type.lower() == 'svm':\n",
    "        try:\n",
    "            model_package = joblib.load(os.path.join(model_dir, 'gpu_svm_model.pkl'))\n",
    "            vectorizer = model_package['vectorizer']\n",
    "            model = model_package['model']\n",
    "            print(\"Loaded GPU SVM model\")\n",
    "        except:\n",
    "            model = joblib.load(os.path.join(model_dir, 'svm_model.pkl'))\n",
    "            print(\"Loaded CPU SVM model\")\n",
    "        \n",
    "        label_encoder = joblib.load(os.path.join(model_dir, 'label_encoder.pkl'))\n",
    "        \n",
    "        def get_prediction(text):\n",
    "            processed = preprocess_text(text)\n",
    "            features = vectorizer.transform([processed])\n",
    "            pred_idx = model.predict(features)[0]\n",
    "            return label_encoder.inverse_transform([pred_idx])[0]\n",
    "    \n",
    "    elif model_type.lower() in ['gru', 'lstm']:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        model_name = model_type.lower()\n",
    "        label_encoder = joblib.load(os.path.join(model_dir, f'label_encoder{\"_lstm\" if model_name == \"lstm\" else \"\"}.pkl'))\n",
    "        vocab = joblib.load(os.path.join(model_dir, f'vocab{\"_lstm\" if model_name == \"lstm\" else \"\"}.pkl'))\n",
    "        \n",
    "        try:\n",
    "            model = torch.load(os.path.join(model_dir, f'complete_{model_name}_model.pt'))\n",
    "            print(f\"Loaded complete {model_name.upper()} model\")\n",
    "        except:\n",
    "            config = joblib.load(os.path.join(model_dir, f'{model_name}_config.pkl'))\n",
    "            from torch import nn\n",
    "            \n",
    "            class GRUClassifier(nn.Module):\n",
    "                def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers=1, dropout=0.5):\n",
    "                    super().__init__()\n",
    "                    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "                    self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=True, batch_first=True, dropout=dropout if n_layers > 1 else 0)\n",
    "                    self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "                    self.dropout = nn.Dropout(dropout)\n",
    "                \n",
    "                def forward(self, text, text_lengths):\n",
    "                    embedded = self.dropout(self.embedding(text))\n",
    "                    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "                    packed_output, hidden = self.gru(packed_embedded)\n",
    "                    hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "                    return self.fc(hidden)\n",
    "            \n",
    "            class LSTMClassifier(nn.Module):\n",
    "                def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers=1, dropout=0.5):\n",
    "                    super().__init__()\n",
    "                    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "                    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=True, batch_first=True, dropout=dropout if n_layers > 1 else 0)\n",
    "                    self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "                    self.dropout = nn.Dropout(dropout)\n",
    "                \n",
    "                def forward(self, text, text_lengths):\n",
    "                    embedded = self.dropout(self.embedding(text))\n",
    "                    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "                    packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "                    hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "                    return self.fc(hidden)\n",
    "            \n",
    "            model_class = GRUClassifier if model_name == 'gru' else LSTMClassifier\n",
    "            model = model_class(config['INPUT_DIM'], config['EMBEDDING_DIM'], config['HIDDEN_DIM'], config['OUTPUT_DIM'], config['N_LAYERS'], config['DROPOUT'])\n",
    "            model.load_state_dict(torch.load(os.path.join(model_dir, f'best_{model_name}_model.pt')))\n",
    "            print(f\"Loaded {model_name.upper()} model from config and weights\")\n",
    "        \n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        def get_prediction(text):\n",
    "            processed = preprocess_text(text)\n",
    "            tokens = word_tokenize(processed)\n",
    "            indices = [vocab.get(token, 1) for token in tokens]\n",
    "            text_tensor = torch.tensor(indices).unsqueeze(0).to(device)\n",
    "            length_tensor = torch.tensor([len(indices)]).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = model(text_tensor, length_tensor)\n",
    "                predicted_idx = torch.argmax(output, dim=1).item()\n",
    "            \n",
    "            return label_encoder.inverse_transform([predicted_idx])[0]\n",
    "    \n",
    "    else:\n",
    "        print(f\"Error: Unknown model type '{model_type}'. Use 'gru', 'lstm', or 'svm'.\")\n",
    "        return\n",
    "    \n",
    "    if index is not None:\n",
    "        entry = dataset.iloc[index]\n",
    "        prediction = get_prediction(entry['text'])\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"Entry #{index}:\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Text: {entry['text']}\")\n",
    "        print(\"-\"*80)\n",
    "        print(f\"Actual label: {entry['label']}\")\n",
    "        print(f\"Predicted label: {prediction}\")\n",
    "        print(f\"Prediction {'correct' if prediction == entry['label'] else 'incorrect'}\")\n",
    "        print(\"=\"*80)\n",
    "    else:\n",
    "        print(\"\\nRunning inference on first 5 entries:\")\n",
    "        for i in range(min(5, len(dataset))):\n",
    "            entry = dataset.iloc[i]\n",
    "            prediction = get_prediction(entry['text'])\n",
    "            print(f\"\\nEntry #{i}: {entry['text'][:100]}...\")\n",
    "            print(f\"Actual: {entry['label']}, Predicted: {prediction}\")\n",
    "            print(\"-\" * 80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11932\\2981657780.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(os.path.join(model_dir, f'complete_{model_name}_model.pt'))\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11932\\2981657780.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(model_dir, f'best_{model_name}_model.pt')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded LSTM model from config and weights\n",
      "\n",
      "================================================================================\n",
      "Entry #30:\n",
      "================================================================================\n",
      "Text: U.S. senator says panel could take up Russia sanctions bill this summer WASHINGTON (Reuters) - The Republican chairman of the U.S. Senate Foreign Relations Committee said on Thursday the panel could take up a bill as soon as this summer to impose new sanctions on Russia over its alleged interference in the 2016 U.S. presidential election. Senator Bob Corker said the panel could move forward on sanctions after hearing from U.S. Secretary of State Rex Tillerson. Some members of the committee, particularly Democrats, had wanted to act more quickly on sanctions over Russian activities that U.S. intelligence agencies concluded were intended to help get Republican Donald Trump elected. Corker said he expects Tillerson to report to the committee within weeks about the Trump administration’s policy toward Russia and the situation in Syria. Corker said he would be willing to consider a sanctions bill soon after that if, as he expected, Tillerson does not demonstrate to the panel that there has been significant change by Russia in Syria, where Moscow has been supporting President Bashar al-Assad in that country’s six-year-old civil war. “I’ve committed to mark up Russia sanctions legislation in the event, the probable event, that the secretary of state cannot show us that there’s a change of trajectory,” Corker said at a committee business meeting. A mark up is a session in which a committee debates legislation and possible amendments. Later in the meeting, the panel overwhelmingly passed legislation to condemn Russian activities including its effort to influence other countries’ elections, aggression in Ukraine and support for Assad. That measure did not include sanctions. Corker and other senators had suggested it would be prudent to wait on sanctions at a delicate time in dealings with Moscow, especially over Syria. Democrats were not pleased at the delay, but said they were willing to wait to hear from the Trump administration. “I do look forward to Mr. Tillerson explaining to us the administration’s Russian policy and what he has seen its impact to be,” said Senator Ben Cardin, the committee’s senior Democrat. If the panel eventually approves sanctions legislation, it would require passage in the full Senate and the House of Representatives before it could go to Trump to sign into law. U.S. intelligence agencies concluded in January that Moscow tried to tilt the 2016 election in Trump’s favor, including by hacking into the emails of senior Democrats. Russia has denied the allegation. Trump has denied any collusion between his campaign and Moscow, but Federal Bureau of Investigation and congressional probes into the matter have dogged the early months of his presidency. Democratic Senator Chris Murphy said it gives many committee members “great pause” that the Trump administration has not acted against Russia for its efforts to influence the election. The United States, under Democratic former President Barack Obama, imposed sanctions on Russia over its actions in Ukraine and in December imposed fresh sanctions and ordered the expulsion of Russian suspected spies over the election meddling. \n",
      "--------------------------------------------------------------------------------\n",
      "Actual label: 0\n",
      "Predicted label: 0\n",
      "Prediction correct\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = 'lstm'  # 'lstm'/'svm'\n",
    "    index = 30      #  Can be none\n",
    "    \n",
    "    # Run inference with the specified model and index\n",
    "    run_inference(model, index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs3264",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
